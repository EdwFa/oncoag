import copy
import json
from typing import Iterable, Dict, Any
import streamlit as st
# import logging
import datetime
# st.set_page_config(
#     page_title="Ex-stream-ly Cool App",
#     page_icon="üßä",
#     layout="wide",
#     initial_sidebar_state="expanded",
#     menu_items={
#         'Get Help': 'https://www.extremelycoolapp.com/help',
#         'Report a bug': "https://www.extremelycoolapp.com/bug",
#         'About': "# This is a header. This is an *extremely* cool app!"
#     }
# )

from streamlit_ace import st_ace
from groq import Groq
import os
import httpx

from moa.agent import MOAgent
from moa.agent.moa import ResponseChunk, MOAgentConfig
from moa.agent.prompts import SYSTEM_PROMPT, REFERENCE_SYSTEM_PROMPT

import textwrap
from fpdf import FPDF



# from pathlib import Path
# from weasyprint import HTML
# import markdown

# Default configuration
default_main_agent_config = {
    "main_model": "qwen-qwq-32b",
    "cycles": 1,
    "temperature": 0.1,
    "system_prompt": SYSTEM_PROMPT,
    "reference_system_prompt": REFERENCE_SYSTEM_PROMPT
}

default_layer_agent_config = {
    "layer_agent_1": {
        "system_prompt": """\
        You are a qualified medical assistant with deep knowledge in the field of oncology. Your task is to assist oncologists in analyzing clinical situations, interpreting examination results, choosing treatment tactics and providing up-to-date scientific information.
        You must:
            Have knowledge of modern protocols for diagnosing and treating oncological diseases.
            Consider the recommendations of international oncological societies (e.g. NCCN, ESMO, ASCO).
            Be familiar with tumor classifications (ICD-10, TNM, histological types).
            Understand the methods of radiation, chemotherapy, targeted, immunotherapy and surgical treatment.
            Facilitate decision-making based on evidence-based medicine and the latest clinical trials.
            Provide information on possible side effects of therapy and ways to correct them.
            Analyze laboratory and instrumental data from the point of view of oncological pathology.
            Do not make a final diagnosis or replace the attending physician, but act as an auxiliary tool for the specialist.
        Your answer should be:
            Scientifically sound
            Clear and structured
            Up-to-date (as of 2024‚Äì2025)
            No unnecessary jargon, but with professional precision
            If necessary, with sources or links to recommendations
       
        Think through your response step by step. {helper_response}",
        """,
        "model_name": "llama-3.3-70b-versatile",
        "temperature": 0.2
    },
    "layer_agent_2": {
        "system_prompt": """\
        You are a qualified medical assistant with deep knowledge in the field of oncology. Your task is to assist oncologists in analyzing clinical situations, interpreting examination results, choosing treatment tactics and providing up-to-date scientific information.
        You must:
            Have knowledge of modern protocols for diagnosing and treating oncological diseases.
            Consider the recommendations of international oncological societies (e.g. NCCN, ESMO, ASCO).
            Be familiar with tumor classifications (ICD-10, TNM, histological types).
            Understand the methods of radiation, chemotherapy, targeted, immunotherapy and surgical treatment.
            Facilitate decision-making based on evidence-based medicine and the latest clinical trials.
            Provide information on possible side effects of therapy and ways to correct them.
            Analyze laboratory and instrumental data from the point of view of oncological pathology.
            Do not make a final diagnosis or replace the attending physician, but act as an auxiliary tool for the specialist.
        Your answer should be:
            Scientifically sound
            Clear and structured
            Up-to-date (as of 2024‚Äì2025)
            No unnecessary jargon, but with professional precision
            If necessary, with sources or links to recommendations
        Respond with a thought and then your response to the question. {helper_response}""",
        "model_name": "deepseek-r1-distill-llama-70b",
        "temperature": 0.2
    },
    "layer_agent_3": {
        "system_prompt": """\
        You are a qualified medical assistant with deep knowledge in the field of oncology. Your task is to assist oncologists in analyzing clinical situations, interpreting examination results, choosing treatment tactics and providing up-to-date scientific information.
        You must:
            Have knowledge of modern protocols for diagnosing and treating oncological diseases.
            Consider the recommendations of international oncological societies (e.g. NCCN, ESMO, ASCO).
            Be familiar with tumor classifications (ICD-10, TNM, histological types).
            Understand the methods of radiation, chemotherapy, targeted, immunotherapy and surgical treatment.
            Facilitate decision-making based on evidence-based medicine and the latest clinical trials.
            Provide information on possible side effects of therapy and ways to correct them.
            Analyze laboratory and instrumental data from the point of view of oncological pathology.
            Do not make a final diagnosis or replace the attending physician, but act as an auxiliary tool for the specialist.
        Your answer should be:
            Scientifically sound
            Clear and structured
            Up-to-date (as of 2024‚Äì2025)
            No unnecessary jargon, but with professional precision
            If necessary, with sources or links to recommendations
        You are an medical expert at logic and reasoning. Always take a logical approach to the answer. {helper_response}
        """,
        "model_name": "gemma2-9b-it",
        "temperature": 0.2
    },
}

# Recommended Configuration
rec_main_agent_config = {
    "main_model": "qwen-qwq-32b",
    "cycles": 1,
    "temperature": 0.1,
    "system_prompt": SYSTEM_PROMPT,
    "reference_system_prompt": REFERENCE_SYSTEM_PROMPT
}

rec_layer_agent_config = {
    "layer_agent_1": {
        "system_prompt": "Think through your response step by step. {helper_response}",
        "model_name": "llama-3.3-70b-versatile",
        "temperature": 0.1
    },
    "layer_agent_2": {
        "system_prompt": "Respond with a thought and then your response to the question. {helper_response}",
        "model_name": "deepseek-r1-distill-llama-70b",
        "temperature": 0.2,
        "max_tokens": 2048
    },
    "layer_agent_3": {
        "system_prompt": "You are an emedical xpert at logic and reasoning. Always take a logical approach to the answer. {helper_response}",
        "model_name": "qwen-qwq-32b",
        "temperature": 0.4,
    },
    "layer_agent_4": {
        "system_prompt": "You are an medical expert planner agent. Create a plan for how to answer the human's query. {helper_response}",
        "model_name": "gemma2-9b-it",
        "temperature": 0.2
    },
}

# === –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ===
LOG_FILE = "oncobot.log"
# logging.basicConfig(
#     level=logging.INFO,
#     format="%(asctime)s %(message)s",
#     handlers=[
#         logging.FileHandler(LOG_FILE, encoding="utf-8"),
#         # logging.StreamHandler()
#     ]
# )

# def log_query(question: str):
#     """–§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –≤–æ–ø—Ä–æ—Å–∞ –∏ –æ—Ç–≤–µ—Ç–∞ –≤ –ª–æ–≥"""
#     logging.info(question)

def write_to_log(filename: str, text: str):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –¥–∞—Ç—ã –∏ –≤—Ä–µ–º–µ–Ω–∏.

    :param filename: –ò–º—è —Ñ–∞–π–ª–∞, –≤ –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∑–∞–ø–∏—Å–∞–Ω —Ç–µ–∫—Å—Ç.
    :param text: –¢–µ–∫—Å—Ç –¥–ª—è –∑–∞–ø–∏—Å–∏.
    """
    # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—É—â–µ–µ –≤—Ä–µ–º—è
    now = datetime.now()
    print(now)
    timestamp = now.strftime("%Y-%m-%d %H:%M:%S")

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É –¥–ª—è –∑–∞–ø–∏—Å–∏
    log_entry = f"[{timestamp}] {text}\n"

    # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –≤ —Ä–µ–∂–∏–º–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –∏ –∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç
    with open(filename, "a", encoding="utf-8") as file:
        file.write(log_entry)

    # print(f"–°–æ–æ–±—â–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∞–Ω–æ –≤ {filename}")


from streamlit.runtime.scriptrunner_utils.script_run_context import get_script_run_ctx
from streamlit.web.server.server import Server


def get_session_id():
    """–ü–æ–ª—É—á–∞–µ—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã–π ID —Å–µ—Å—Å–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    ctx = get_script_run_ctx()
    if ctx is None:
        return "unknown_session"
    return ctx.session_id


def _get_session():
    from streamlit.runtime import get_instance
    from streamlit.runtime.scriptrunner import get_script_run_ctx
    runtime = get_instance()
    session_id = get_script_run_ctx().session_id
    session_info = runtime._session_mgr.get_session_info(session_id)
    if session_info is None:
        raise RuntimeError("Couldn't get your Streamlit Session object.")
    return session_info

def get_client_ip():
    """–ü—ã—Ç–∞–µ—Ç—Å—è –ø–æ–ª—É—á–∏—Ç—å IP-–∞–¥—Ä–µ—Å –∫–ª–∏–µ–Ω—Ç–∞"""
    session_info = _get_session()
    if session_info is None:
        return "unknown_ip"
    print(session_info)
    return
    # –ü–æ–ª—É—á–∞–µ–º IP –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∑–∞–ø—Ä–æ—Å–∞
    headers = session_info.request.headers
    x_forwarded_for = headers.get("X-Forwarded-For")
    if x_forwarded_for:
        return x_forwarded_for.split(",")[0].strip()
    remote_ip = headers.get("Remote-Addr")
    return remote_ip or "unknown_ip"


def write_to_file_with_metadata(filename: str, question: str):
    """
    –ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ —Ñ–∞–π–ª –≤–º–µ—Å—Ç–µ —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏:
    - –î–∞—Ç–∞ –∏ –≤—Ä–µ–º—è
    - Session ID
    - IP-–∞–¥—Ä–µ—Å

    :param filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏
    :param question: –¢–µ–∫—Å—Ç –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    """
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    session_id = get_session_id()
    ip_address = get_client_ip()

    log_entry = f"[{timestamp}] [IP: {ip_address}] [Session: {session_id}] Question: {question}\n"

    with open(filename, "a", encoding="utf-8") as file:
        file.write(log_entry)

    st.info(f"–í–æ–ø—Ä–æ—Å –∑–∞–ø–∏—Å–∞–Ω –≤ –ª–æ–≥: {log_entry.strip()}")


def view_file_contents(filename: str):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ Streamlit.
    :param filename: –ò–º—è —Ñ–∞–π–ª–∞, —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∫–æ—Ç–æ—Ä–æ–≥–æ –Ω—É–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å.
    """
    try:
        with open(filename, "r", encoding="utf-8") as file:
            content = file.read()
        if content:
            st.text_area("–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞:", value=content, height=400)
        else:
            st.info("–§–∞–π–ª –ø—É—Å—Ç.")
    except FileNotFoundError:
        st.error(f"–§–∞–π–ª '{filename}' –Ω–µ –Ω–∞–π–¥–µ–Ω.")

from datetime import datetime
def download_log_button(log_file_path: str = "oncobot.log"):
    """
    –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –∫–Ω–æ–ø–∫—É '–°–∫–∞—á–∞—Ç—å –ª–æ–≥' –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª —Å –ª–æ–≥–∞–º–∏.

    :param log_file_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –ª–æ–≥–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 'user_questions.log')
    """
    try:
        with open(log_file_path, "rb") as f:
            log_data = f.read()

        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∏–º—è —Ñ–∞–π–ª–∞ —Å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –º–µ—Ç–∫–æ–π
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        downloadable_name = f"log_{timestamp}.txt"

        st.download_button(
            label="üîΩ –°–∫–∞—á–∞—Ç—å –ª–æ–≥",
            data=log_data,
            file_name=downloadable_name,
            mime="text/plain",
            key="download_log_button"
        )

    except FileNotFoundError:
        st.warning("–§–∞–π–ª –ª–æ–≥–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∫–∞ –Ω–µ—Ç –∑–∞–ø–∏—Å–µ–π –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è.")


# –ö–ª—é—á–∏ –∏–Ω—Ç–µ—Ä=—Ñ–µ–π—Å–æ–≤
# GROQ_API_KEY = "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" - —Å—Ç–∞—Ä—ã–π
# GROQ_API_KEY = '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'
GROQ_API_KEY = os.environ.get("GROQ_API_KEY", default=None)
# print(GROQ_API_KEY)

# client = Groq(
#     api_key=os.environ.get("GROQ_API_KEY"),
#     http_client=httpx.Client(verify=False)  # Disable SSL verification
# )
# os.environ['GROQ_API_KEY'] = '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'
# print(GROQ_API_KEY)
if 'api_key' not in st.session_state:
    st.session_state.api_key = GROQ_API_KEY
if 'groq' not in st.session_state:
    if GROQ_API_KEY:
        # st.session_state.groq = Groq()
        st.session_state.groq = Groq(
            api_key=os.environ.get("GROQ_API_KEY"),
            http_client=httpx.Client(verify=False)  # Disable SSL verification
        )


# Helper functions
def json_to_moa_config(config_file) -> Dict[str, Any]:
    config = json.load(config_file)
    moa_config = MOAgentConfig( # To check if everything is ok
        **config
    ).model_dump(exclude_unset=True)
    return {
        'moa_layer_agent_config':moa_config.pop('layer_agent_config', None),
        'moa_main_agent_config': moa_config or None
    }

def stream_response(messages: Iterable[ResponseChunk]):
    layer_outputs = {}
    for message in messages:
        if message['response_type'] == 'intermediate':
            layer = message['metadata']['layer']
            if layer not in layer_outputs:
                layer_outputs[layer] = []
            layer_outputs[layer].append(message['delta'])
        else:
            # Display accumulated layer outputs
            for layer, outputs in layer_outputs.items():
                st.write(f"Layer {layer}")
                cols = st.columns(len(outputs))
                for i, output in enumerate(outputs):
                    with cols[i]:
                        st.expander(label=f"Agent {i+1}", expanded=False).write(output)
            
            # Clear layer outputs for the next iteration
            layer_outputs = {}
            
            # Yield the main agent's output
            yield message['delta']

def set_moa_agent(
    moa_main_agent_config = None,
    moa_layer_agent_config = None,
    override: bool = False
):
    moa_main_agent_config = copy.deepcopy(moa_main_agent_config or default_main_agent_config)
    moa_layer_agent_config = copy.deepcopy(moa_layer_agent_config or default_layer_agent_config)

    if "moa_main_agent_config" not in st.session_state or override:
        st.session_state.moa_main_agent_config = moa_main_agent_config

    if "moa_layer_agent_config" not in st.session_state or override:
        st.session_state.moa_layer_agent_config = moa_layer_agent_config

    if override or ("moa_agent" not in st.session_state):
        st_main_copy = copy.deepcopy(st.session_state.moa_main_agent_config)
        st_layer_copy = copy.deepcopy(st.session_state.moa_layer_agent_config)
        st.session_state.moa_agent = MOAgent.from_config(
            **st_main_copy,
            layer_agent_config=st_layer_copy
        )

        del st_main_copy
        del st_layer_copy

    del moa_main_agent_config
    del moa_layer_agent_config

# App
st.set_page_config(
    page_title="Sechenov Onco-LLMAgents ",
    page_icon='static/favicon.ico',
         menu_items={
        'About': "## LLM-Onco-Agents-SU"
    },
    layout="wide",
    initial_sidebar_state="collapsed",
)

# valid_model_names = [model.id for model in Groq().models.list().data if not (model.id.startswith("whisper") or model.id.startswith("llama-guard"))]

valid_model_names = [
    'llama-3.3-70b-versatile',
    'gemma2-9b-it',
    'mistral-saba-24b',
    'meta-llama/llama-4-maverick-17b-128e-instruct',
    'qwen-qwq-32b',
    'deepseek-r1-distill-llama-70b'
]


# st.markdown("<a href='https://groq.com'><img src='app/static/banner.png' width='500'></a>", unsafe_allow_html=True)
# st.write("---")

# Initialize session state
if "messages" not in st.session_state:
    st.session_state.messages = []

set_moa_agent()

# Sidebar for configuration
with st.sidebar:
    st.title("Configuration")
    # upl_col, load_col = st.columns(2)
    st.download_button(
        "Download",
        data=json.dumps({
            **st.session_state.moa_main_agent_config,
            'moa_layer_agent_config': st.session_state.moa_layer_agent_config
        }, indent=2),
        file_name="moa_config.json"
    )

    # moa_config_upload = st.file_uploader("Choose a JSON file", type="json")
    # submit_config_file = st.button("Update config")
    # if moa_config_upload and submit_config_file:
    #     try:
    #         moa_config = json_to_moa_config(moa_config_upload)
    #         set_moa_agent(
    #             moa_main_agent_config=moa_config['moa_main_agent_config'],
    #             moa_layer_agent_config=moa_config['moa_layer_agent_config']
    #         )
    #         st.session_state.messages = []
    #         st.success("Configuration updated successfully!")
    #     except Exception as e:
    #         st.error(f"Error loading file: {str(e)}")

    with st.form("Agents ..", border=False):
        # Load and Save moa config file

        if st.form_submit_button("Use Recommended Config"):
            try:
                set_moa_agent(
                    moa_main_agent_config=rec_main_agent_config,
                    moa_layer_agent_config=rec_layer_agent_config,
                    override=True
                )
                st.session_state.messages = []
                st.success("Configuration updated successfully!")
            except json.JSONDecodeError:
                st.error("Invalid JSON in Layer Agent Configuration. Please check your input.")
            except Exception as e:
                st.error(f"Error updating configuration: {str(e)}")

        # Main model selection
        new_main_model = st.selectbox(
            "Main Model",
            options=valid_model_names,
            index=valid_model_names.index(st.session_state.moa_main_agent_config['main_model'])
        )

        # Cycles input
        new_cycles = st.number_input(
            "Iterations",
            min_value=1,
            max_value=10,
            value=st.session_state.moa_main_agent_config['cycles']
        )

        # Main Model Temperature
        main_temperature = st.number_input(
            label="Main-Agent Temperature",
            value=0.1,
            min_value=0.0,
            max_value=1.0,
            step=0.1
        )

        # Layer agent configuration
        tooltip = "Agents in the layer agent configuration run in parallel _per cycle_. Each layer agent supports all initialization parameters of [Langchain's ChatGroq](https://api.python.langchain.com/en/latest/chat_models/langchain_groq.chat_models.ChatGroq.html) class as valid dictionary fields."
        st.markdown("Layers", help=tooltip)
        new_layer_agent_config = st_ace(
            key="layer_agent_config",
            value=json.dumps(st.session_state.moa_layer_agent_config, indent=2),
            language='json',
            placeholder="Layer Agent Configuration (JSON)",
            show_gutter=False,
            wrap=True,
            auto_update=True
        )

        with st.expander("Optional Main Agent Params", expanded=True):
            tooltip_str = """\
Main Agent configuration that will respond to the user based on the layer agent outputs.
Valid fields:
- ``system_prompt``: System prompt given to the main agent. \
**IMPORTANT**: it should always include a `{helper_response}` prompt variable.
- ``reference_prompt``: This prompt is used to concatenate and format each layer agent's output into one string. \
This is passed into the `{helper_response}` variable in the system prompt. \
**IMPORTANT**: it should always include a `{responses}` prompt variable. 
- ``main_model``: Which Groq powered model to use. Will overwrite the model given in the dropdown.\
"""
            tooltip = tooltip_str
            st.markdown("Main Agent Config", help=tooltip)
            new_main_agent_config = st_ace(
                key="main_agent_params",
                value=json.dumps(st.session_state.moa_main_agent_config, indent=2),
                language='json',
                placeholder="Main Agent Configuration (JSON)",
                show_gutter=False,
                wrap=True,
                auto_update=True
            )

        if st.form_submit_button("Update Configuration"):
            try:
                new_layer_config = json.loads(new_layer_agent_config)
                new_main_config = json.loads(new_main_agent_config)
                # Configure conflicting params
                # If param in optional dropdown == default param set, prefer using explicitly defined param
                if new_main_config.get('main_model', default_main_agent_config['main_model']) == default_main_agent_config["main_model"]:
                    new_main_config['main_model'] = new_main_model
                
                if new_main_config.get('cycles', default_main_agent_config['cycles']) == default_main_agent_config["cycles"]:
                    new_main_config['cycles'] = new_cycles

                if new_main_config.get('temperature', default_main_agent_config['temperature']) == default_main_agent_config['temperature']:
                    new_main_config['temperature'] = main_temperature
                
                set_moa_agent(
                    moa_main_agent_config=new_main_config,
                    moa_layer_agent_config=new_layer_config,
                    override=True
                )
                st.session_state.messages = []
                st.success("Configuration updated successfully!")
            except json.JSONDecodeError:
                st.error("Invalid JSON in Layer Agent Configuration. Please check your input.")
            except Exception as e:
                st.error(f"Error updating configuration: {str(e)}")

        if st.form_submit_button("Logview"):
            view_file_contents(LOG_FILE)
        # if st.form_submit_button("Download"):
    download_log_button(log_file_path="oncobot.log")

    # st.markdown("---")
    # st.markdown("""
    # ### Credits
    # - MOA: [Together AI](https://www.together.ai/blog/together-moa)
    # - LLMs: [Groq](https://groq.com/)
    # - Paper: [arXiv:2406.04692](https://arxiv.org/abs/2406.04692)
    # """)


def text_to_pdf(text, filename):
    a4_width_mm = 210
    pt_to_mm = 0.35
    fontsize_pt = 10
    fontsize_mm = fontsize_pt * pt_to_mm
    margin_bottom_mm = 10
    character_width_mm = 7 * pt_to_mm
    width_text = a4_width_mm / character_width_mm
    pdf = FPDF(orientation='P', unit='mm', format='A4')
    pdf.set_auto_page_break(True, margin=margin_bottom_mm)
    pdf.add_page()
    pdf.set_font(family='Arial', size=fontsize_pt)
    splitted = text.split('\n')
    for line in splitted:
        lines = textwrap.wrap(line, width_text)
        if len(lines) == 0:
            pdf.ln()
        for wrap in lines:
            pdf.cell(0, fontsize_mm, wrap, ln=1)
    pdf.output(filename, 'F')

def save_markdown(text: str, filename: str) -> bool:
    """
    –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –≤ —Ñ–∞–π–ª —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º –∏–º–µ–Ω–µ–º.

    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
    text (str): –¢–µ–∫—Å—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ Markdown –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
    filename (str): –ò–º—è —Ü–µ–ª–µ–≤–æ–≥–æ —Ñ–∞–π–ª–∞ (—Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .md –∏–ª–∏ –±–µ–∑)

    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
    bool: True –µ—Å–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, False –≤ —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏
    """
    try:
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ .md –µ—Å–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç
        if not filename.endswith('.md'):
            filename += '.md'

        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        dir_path = os.path.dirname(filename)
        if dir_path and not os.path.exists(dir_path):
            os.makedirs(dir_path)

        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –≤ —Ñ–∞–π–ª
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(text)

        return True

    except Exception as e:
        print(f'–û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {str(e)}')
        return False

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# if __name__ == "__main__":
#     content = """# –ü—Ä–∏–º–µ—Ä Markdown
#
# ## –°–ø–∏—Å–æ–∫ –¥–µ–ª
# - [x] –ù–∞–ø–∏—Å–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
# - [ ] –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥
# - [ ] –î–æ–±–∞–≤–∏—Ç—å –≤ –ø—Ä–æ–µ–∫—Ç
#
# ```python
# print("Hello Markdown!")
# ```"""
#
#     if save_markdown(content, 'example_file'):
#         print("–§–∞–π–ª —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω!")
#     else:
#         print("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ñ–∞–π–ª")



# def md_to_pdf(input_md: str, output_pdf: str, css: str = None) -> bool:
#     """
#     –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç Markdown-—Ñ–∞–π–ª –≤ PDF —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
#
#     –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
#     input_md (str): –ü—É—Ç—å –∫ –∏—Å—Ö–æ–¥–Ω–æ–º—É .md —Ñ–∞–π–ª—É
#     output_pdf (str): –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è .pdf —Ñ–∞–π–ª–∞
#     css (str): –û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—É—Ç—å –∫ CSS-—Ñ–∞–π–ª—É –¥–ª—è —Å—Ç–∏–ª–∏–∑–∞—Ü–∏–∏ PDF
#
#     –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
#     bool: True –ø—Ä–∏ —É—Å–ø–µ—à–Ω–æ–π –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏, False –ø—Ä–∏ –æ—à–∏–±–∫–µ
#     """
#     try:
#         # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–π —Ñ–∞–π–ª–æ–≤
#         if not input_md.endswith('.md'):
#             raise ValueError("Input file must be a .md file")
#
#         if not output_pdf.endswith('.pdf'):
#             output_pdf += '.pdf'
#
#         # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π –¥–ª—è –≤—ã—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
#         Path(output_pdf).parent.mkdir(parents=True, exist_ok=True)
#
#         # –ß—Ç–µ–Ω–∏–µ Markdown-–∫–æ–Ω—Ç–µ–Ω—Ç–∞
#         with open(input_md, 'r', encoding='utf-8') as f:
#             md_content = f.read()
#
#         # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è Markdown –≤ HTML
#         html_content = markdown.markdown(md_content)
#
#         # –ë–∞–∑–æ–≤—ã–µ CSS-—Å—Ç–∏–ª–∏
#         default_css = """
#         body { font-family: Arial, sans-serif; line-height: 1.6; margin: 2cm; }
#         h1, h2, h3 { color: #2c3e50; }
#         code { background: #f4f4f4; padding: 2px 5px; border-radius: 3px; }
#         pre { background: #333; color: #fff; padding: 15px; overflow-x: auto; }
#         a { color: #3498db; text-decoration: none; }
#         """
#
#         # –°–±–æ—Ä–∫–∞ –ø–æ–ª–Ω–æ–≥–æ HTML-–¥–æ–∫—É–º–µ–Ω—Ç–∞
#         full_html = f"""
#         <!DOCTYPE html>
#         <html>
#             <head>
#                 <meta charset="utf-8">
#                 <style>{default_css}</style>
#                 {f'<link rel="stylesheet" href="{css}">' if css else ''}
#             </head>
#             <body>{html_content}</body>
#         </html>
#         """
#
#         # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è PDF
#         HTML(string=full_html).write_pdf(output_pdf)
#
#         return True
#
#     except Exception as e:
#         print(f"–û—à–∏–±–∫–∞ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏: {str(e)}")
#         return False


# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
# if __name__ == "__main__":
#     if md_to_pdf('example_file.md', 'output.pdf'):
#         print("PDF —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
#     else:
#         print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PDF")


# Main app layout
st.header("Sechenov Onco Assistant-&-Consultant", anchor=False, divider='blue')
st.write("Prototype Oncology medical AI-consultant, Powered by Sechenov University on GroQ")

# Display current configuration
with st.status("Current Configuration", expanded=False, state='complete') as config_status:
    # st.image("./static/moa_groq.svg", caption="Mixture of Agents Workflow", use_column_width='always')
    st.markdown(f"**Main Agent Config**:")
    new_layer_agent_config = st_ace(
        value=json.dumps(st.session_state.moa_main_agent_config, indent=2),
        language='json',
        placeholder="Layer Agent Configuration (JSON)",
        show_gutter=False,
        wrap=True,
        readonly=True,
        auto_update=True
    )
    st.markdown(f"**Layer Agents Config**:")
    new_layer_agent_config = st_ace(
        value=json.dumps(st.session_state.moa_layer_agent_config, indent=2),
        language='json',
        placeholder="Layer Agent Configuration (JSON)",
        show_gutter=False,
        wrap=True,
        readonly=True,
        auto_update=True
    )

if st.session_state.get("message", []) != []:
    st.session_state['expand_config'] = False

# Chat interface
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        # text_to_pdf(message["content"], 'reports/report.pdf')
        # print(message["content"])
        st.markdown(message["content"])


if query := st.chat_input("Ask a question"):
    config_status.update(expanded=False)
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.write(query)
        # write_to_file_with_metadata(LOG_FILE, query)
        write_to_log(LOG_FILE, query)
        # print(query)
        # logging.info(query)


    moa_agent: MOAgent = st.session_state.moa_agent
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        ast_mess = stream_response(moa_agent.chat(query, output_format='json'))
        response = st.write_stream(ast_mess)
        save_markdown(response, 'result.md')
        # if md_to_pdf('result.md', 'output.pdf'):
        #     print("PDF —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω!")
        # else:
        #     print("–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ PDF")
        # print(response)
    
    st.session_state.messages.append({"role": "assistant", "content": response})